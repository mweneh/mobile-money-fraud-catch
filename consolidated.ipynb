{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360703a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Set style\u001b[39;00m\n\u001b[1;32m     33\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn-v0_8-darkgrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FRAUD DETECTION ANALYSIS - STREAMLINED VERSION\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional: Plotly for interactive visualizations\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. DATA LOADING & INITIAL ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_assess_data(train_path, test_path):\n",
    "    \"\"\"Load data and perform initial quality assessment\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"DATA LOADING & QUALITY ASSESSMENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    \n",
    "    # Quick summary\n",
    "    print(f\"\\nTrain shape: {train.shape}, Test shape: {test.shape}\")\n",
    "    print(f\"Fraud rate: {train['FraudResult'].mean():.2%}\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing_train = train.isnull().sum()\n",
    "    if missing_train.sum() > 0:\n",
    "        print(f\"\\nMissing values in train:\\n{missing_train[missing_train > 0]}\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"\\nData types: {train.dtypes.value_counts().to_dict()}\")\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# =============================================================================\n",
    "# 2. COMPREHENSIVE EDA (CONSOLIDATED)\n",
    "# =============================================================================\n",
    "\n",
    "def perform_eda(train, create_interactive=False):\n",
    "    \"\"\"Consolidated EDA with key visualizations\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Parse datetime\n",
    "    train['TransactionStartTime'] = pd.to_datetime(train['TransactionStartTime'])\n",
    "    train['Hour'] = train['TransactionStartTime'].dt.hour\n",
    "    train['DayOfWeek'] = train['TransactionStartTime'].dt.day_name()\n",
    "    train['Date'] = train['TransactionStartTime'].dt.date\n",
    "    \n",
    "    # Create comprehensive dashboard\n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Fraud distribution\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    fraud_counts = train['FraudResult'].value_counts()\n",
    "    ax1.pie(fraud_counts.values, labels=['Legitimate', 'Fraud'], \n",
    "            autopct='%1.1f%%', colors=['#2E86C1', '#E74C3C'],\n",
    "            wedgeprops={'width': 0.4})\n",
    "    ax1.set_title('Fraud Distribution', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # 2. Hourly fraud rate\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    hourly_fraud = train.groupby('Hour')['FraudResult'].agg(['sum', 'count', 'mean'])\n",
    "    ax2.bar(hourly_fraud.index, hourly_fraud['mean'], color='orange', alpha=0.7)\n",
    "    ax2.set_xlabel('Hour'); ax2.set_ylabel('Fraud Rate')\n",
    "    ax2.set_title('Hourly Fraud Pattern')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Daily fraud trend\n",
    "    ax3 = fig.add_subplot(gs[0, 2:4])\n",
    "    daily_fraud = train.groupby('Date')['FraudResult'].mean()\n",
    "    ax3.plot(daily_fraud.index, daily_fraud.values, color='red', linewidth=2)\n",
    "    ax3.set_xlabel('Date'); ax3.set_ylabel('Fraud Rate')\n",
    "    ax3.set_title('Daily Fraud Trend')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # 4. Amount distribution\n",
    "    ax4 = fig.add_subplot(gs[1, 0:2])\n",
    "    legitimate = train[train['FraudResult']==0]['Amount']\n",
    "    fraud = train[train['FraudResult']==1]['Amount']\n",
    "    ax4.hist(legitimate, bins=50, alpha=0.6, label='Legitimate', density=True)\n",
    "    ax4.hist(fraud, bins=50, alpha=0.6, label='Fraud', density=True)\n",
    "    ax4.set_xlabel('Amount'); ax4.set_ylabel('Density')\n",
    "    ax4.set_title('Amount Distribution by Fraud Status')\n",
    "    ax4.set_xlim(0, train['Amount'].quantile(0.95))\n",
    "    ax4.legend()\n",
    "    \n",
    "    # 5. Amount vs Value scatter\n",
    "    ax5 = fig.add_subplot(gs[1, 2:4])\n",
    "    sample = train.sample(min(5000, len(train)))\n",
    "    scatter = ax5.scatter(sample['Amount'], sample['Value'], \n",
    "                         c=sample['FraudResult'], cmap='RdYlBu_r', alpha=0.5, s=10)\n",
    "    ax5.set_xlabel('Amount'); ax5.set_ylabel('Value')\n",
    "    ax5.set_title('Amount vs Value (Fraud Colored)')\n",
    "    plt.colorbar(scatter, ax=ax5)\n",
    "    \n",
    "    # 6. Correlation heatmap\n",
    "    ax6 = fig.add_subplot(gs[2, 0:2])\n",
    "    numeric_cols = train.select_dtypes(include=[np.number]).columns\n",
    "    corr_matrix = train[numeric_cols].corr()\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "                cmap='RdYlBu_r', center=0, ax=ax6, cbar_kws={'shrink': 0.8})\n",
    "    ax6.set_title('Feature Correlations')\n",
    "    \n",
    "    # 7. Feature correlation with target\n",
    "    ax7 = fig.add_subplot(gs[2, 2:4])\n",
    "    target_corr = corr_matrix['FraudResult'].drop('FraudResult').sort_values(key=abs)\n",
    "    colors = ['red' if x > 0 else 'blue' for x in target_corr.values]\n",
    "    ax7.barh(range(len(target_corr)), target_corr.values, color=colors, alpha=0.7)\n",
    "    ax7.set_yticks(range(len(target_corr)))\n",
    "    ax7.set_yticklabels(target_corr.index, fontsize=9)\n",
    "    ax7.set_xlabel('Correlation with Fraud')\n",
    "    ax7.set_title('Feature Importance (Correlation)')\n",
    "    ax7.grid(alpha=0.3)\n",
    "    ax7.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\n",
    "    \n",
    "    plt.suptitle('Fraud Detection - Comprehensive EDA Dashboard', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key insights\n",
    "    print(f\"\\nðŸ“Š KEY INSIGHTS:\")\n",
    "    print(f\"â€¢ Peak fraud hour: {hourly_fraud['mean'].idxmax()}:00 ({hourly_fraud['mean'].max():.1%})\")\n",
    "    print(f\"â€¢ Average daily fraud: {daily_fraud.mean():.2%}\")\n",
    "    print(f\"â€¢ Amount: Legit avg={legitimate.mean():.2f}, Fraud avg={fraud.mean():.2f}\")\n",
    "    print(f\"â€¢ Top correlations: {target_corr.tail(3).to_dict()}\")\n",
    "    \n",
    "    # Optional: Interactive dashboard\n",
    "    if create_interactive and PLOTLY_AVAILABLE:\n",
    "        create_interactive_dashboard(train, hourly_fraud, daily_fraud)\n",
    "    \n",
    "    return train\n",
    "\n",
    "def create_interactive_dashboard(train, hourly_fraud, daily_fraud):\n",
    "    \"\"\"Create interactive Plotly dashboard\"\"\"\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Fraud Distribution', 'Daily Trend', \n",
    "                       'Hourly Pattern', 'Amount by Status'),\n",
    "        specs=[[{\"type\": \"pie\"}, {\"type\": \"xy\"}],\n",
    "               [{\"type\": \"xy\"}, {\"type\": \"box\"}]]\n",
    "    )\n",
    "    \n",
    "    # Fraud pie\n",
    "    fraud_counts = train['FraudResult'].value_counts()\n",
    "    fig.add_trace(go.Pie(labels=['Legitimate', 'Fraud'], \n",
    "                         values=[fraud_counts[0], fraud_counts[1]],\n",
    "                         hole=0.4), row=1, col=1)\n",
    "    \n",
    "    # Daily trend\n",
    "    fig.add_trace(go.Scatter(x=daily_fraud.index, y=daily_fraud.values,\n",
    "                            mode='lines+markers', name='Daily Rate'),\n",
    "                 row=1, col=2)\n",
    "    \n",
    "    # Hourly pattern\n",
    "    fig.add_trace(go.Bar(x=hourly_fraud.index, y=hourly_fraud['mean'],\n",
    "                        name='Hourly Rate'), row=2, col=1)\n",
    "    \n",
    "    # Amount boxes\n",
    "    fig.add_trace(go.Box(y=train[train['FraudResult']==0]['Amount'],\n",
    "                        name='Legitimate'), row=2, col=2)\n",
    "    fig.add_trace(go.Box(y=train[train['FraudResult']==1]['Amount'],\n",
    "                        name='Fraud'), row=2, col=2)\n",
    "    \n",
    "    fig.update_layout(height=800, showlegend=True, \n",
    "                     title_text=\"Interactive Fraud Dashboard\")\n",
    "    fig.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 3. FEATURE ENGINEERING (CONSOLIDATED)\n",
    "# =============================================================================\n",
    "\n",
    "def engineer_features(train):\n",
    "    \"\"\"Create all engineered features in one place\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FEATURE ENGINEERING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    df = train.copy()\n",
    "    \n",
    "    # Ensure datetime is parsed\n",
    "    if df['TransactionStartTime'].dtype == 'object':\n",
    "        df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])\n",
    "    \n",
    "    # Time features\n",
    "    df['Hour'] = df['TransactionStartTime'].dt.hour\n",
    "    df['DayOfWeek'] = df['TransactionStartTime'].dt.dayofweek\n",
    "    df['IsWeekend'] = df['DayOfWeek'].isin([5, 6]).astype(int)\n",
    "    df['IsBusinessHour'] = ((df['Hour'] >= 9) & (df['Hour'] <= 17)).astype(int)\n",
    "    df['IsLateNight'] = ((df['Hour'] >= 22) | (df['Hour'] <= 6)).astype(int)\n",
    "    \n",
    "    # Amount/Value features\n",
    "    df['Amount_Value_Ratio'] = df['Amount'] / (df['Value'] + 1e-6)\n",
    "    df['Amount_Value_Diff'] = df['Amount'] - df['Value']\n",
    "    df['Amount_Value_Interaction'] = df['Amount'] * df['Value']\n",
    "    df['LogAmount'] = np.log1p(df['Amount'])\n",
    "    df['LogValue'] = np.log1p(df['Value'])\n",
    "    \n",
    "    # Risk score (composite feature)\n",
    "    df['RiskScore'] = (\n",
    "        df['Amount'].rank(pct=True) * 0.3 +\n",
    "        df['LogAmount'].rank(pct=True) * 0.3 +\n",
    "        df['IsLateNight'] * 0.2 +\n",
    "        df['IsWeekend'] * 0.1 +\n",
    "        df['Amount_Value_Ratio'].rank(pct=True) * 0.1\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Created {len(df.columns) - len(train.columns)} new features\")\n",
    "    print(f\"Feature list: {[c for c in df.columns if c not in train.columns]}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# =============================================================================\n",
    "# 4. MODEL TRAINING & EVALUATION (CONSOLIDATED)\n",
    "# =============================================================================\n",
    "\n",
    "def train_and_evaluate_models(train):\n",
    "    \"\"\"Train multiple models and compare performance\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL TRAINING & EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_cols = [col for col in train.columns \n",
    "                   if col not in ['FraudResult', 'TransactionStartTime', \n",
    "                                  'Date', 'DayOfWeek'] \n",
    "                   and train[col].dtype in [np.number, 'int64', 'float64']]\n",
    "    \n",
    "    X = train[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    y = train['FraudResult']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Define models\n",
    "    models = {\n",
    "        \"LightGBM\": LGBMClassifier(n_estimators=300, learning_rate=0.05,\n",
    "                                  class_weight=\"balanced\", random_state=42, verbose=-1),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=300, learning_rate=0.05,\n",
    "                                scale_pos_weight=len(y_train[y_train==0])/len(y_train[y_train==1]),\n",
    "                                use_label_encoder=False, eval_metric=\"logloss\", \n",
    "                                random_state=42),\n",
    "        \"LinearSVM\": make_pipeline(StandardScaler(), \n",
    "                                  LinearSVC(class_weight='balanced', \n",
    "                                           dual=False, max_iter=5000, random_state=42))\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Train and evaluate\n",
    "    fig, axes = plt.subplots(len(models), 2, figsize=(14, 5*len(models)))\n",
    "    if len(models) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "        print(f\"\\nðŸš€ Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Handle probability/decision function\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_proba = model.decision_function(X_test)\n",
    "        \n",
    "        # Metrics\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        report = classification_report(y_test, y_pred, zero_division=0)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'roc_auc': roc_auc,\n",
    "            'report': report,\n",
    "            'confusion_matrix': cm,\n",
    "            'model': model\n",
    "        }\n",
    "        \n",
    "        # Plot ROC and PR curves\n",
    "        RocCurveDisplay.from_estimator(model, X_test, y_test, ax=axes[idx, 0])\n",
    "        axes[idx, 0].set_title(f\"{name} - ROC Curve (AUC={roc_auc:.3f})\")\n",
    "        \n",
    "        PrecisionRecallDisplay.from_estimator(model, X_test, y_test, ax=axes[idx, 1])\n",
    "        axes[idx, 1].set_title(f\"{name} - Precision-Recall Curve\")\n",
    "        \n",
    "        print(f\"\\n{name} Results:\")\n",
    "        print(report)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Model comparison\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL COMPARISON SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    comparison_df = pd.DataFrame({\n",
    "        name: {'ROC-AUC': res['roc_auc']} \n",
    "        for name, res in results.items()\n",
    "    }).T.sort_values('ROC-AUC', ascending=False)\n",
    "    print(comparison_df.to_string())\n",
    "    \n",
    "    return results, X_test, y_test\n",
    "\n",
    "# =============================================================================\n",
    "# 5. MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline\"\"\"\n",
    "    \n",
    "    # 1. Load data\n",
    "    train, test = load_and_assess_data(\n",
    "        'training.csv',\n",
    "        'test.csv'\n",
    "    )\n",
    "    \n",
    "    # 2. EDA\n",
    "    train = perform_eda(train, create_interactive=False)\n",
    "    \n",
    "    # 3. Feature engineering\n",
    "    train = engineer_features(train)\n",
    "    \n",
    "    # 4. Model training\n",
    "    results, X_test, y_test = train_and_evaluate_models(train)\n",
    "    \n",
    "    # 5. Save processed data (optional)\n",
    "    # train.to_csv('processed_fraud_data.csv', index=False)\n",
    "    \n",
    "    print(\"\\nâœ… ANALYSIS COMPLETE!\")\n",
    "    print(f\"Best model: {max(results.items(), key=lambda x: x[1]['roc_auc'])[0]}\")\n",
    "    \n",
    "    return train, results\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    train, results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb10f8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
